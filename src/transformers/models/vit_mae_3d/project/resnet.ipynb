{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNetConfig {\n",
      "  \"depths\": [\n",
      "    3,\n",
      "    4,\n",
      "    6,\n",
      "    3\n",
      "  ],\n",
      "  \"downsample_in_first_stage\": false,\n",
      "  \"embedding_size\": 64,\n",
      "  \"hidden_act\": \"relu\",\n",
      "  \"hidden_sizes\": [\n",
      "    256,\n",
      "    512,\n",
      "    1024,\n",
      "    2048\n",
      "  ],\n",
      "  \"layer_type\": \"bottleneck\",\n",
      "  \"model_type\": \"resnet\",\n",
      "  \"num_channels\": 91,\n",
      "  \"num_classes\": 2,\n",
      "  \"out_features\": [\n",
      "    \"stage4\"\n",
      "  ],\n",
      "  \"out_indices\": [\n",
      "    4\n",
      "  ],\n",
      "  \"stage_names\": [\n",
      "    \"stem\",\n",
      "    \"stage1\",\n",
      "    \"stage2\",\n",
      "    \"stage3\",\n",
      "    \"stage4\"\n",
      "  ],\n",
      "  \"transformers_version\": \"4.30.0.dev0\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import ResNetConfig, ResNetForImageClassification\n",
    "\n",
    "config = ResNetConfig(\n",
    "    num_channels=91,\n",
    "    num_classes=2,\n",
    ")\n",
    "\n",
    "model = ResNetForImageClassification(config)\n",
    "\n",
    "_config = model.config\n",
    "print(_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# open files.txt which contains all the file paths\n",
    "with open('/home/minghui/github/NMSS/vitmae/files.txt', 'r') as f:\n",
    "    files = f.readlines()\n",
    "files = [x.strip() for x in files]\n",
    "\n",
    "# split data into train, val and test set\n",
    "random.shuffle(files)\n",
    "train_set = files[:int(len(files)*0.8)]\n",
    "val_set = files[int(len(files)*0.8):int(len(files)*0.9)]\n",
    "test_set = files[int(len(files)*0.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import csv\n",
    "import torch\n",
    "import numpy as np\n",
    "from einops import rearrange\n",
    "from torch.utils.data import Dataset\n",
    "from monai.data import NibabelReader\n",
    "\n",
    "class SPRINT_T1w_flat_Dataset:\n",
    "    def __init__(self, data_dir, filenames, subjects_csv, mode='train', transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        # read all nifti files in data_dir\n",
    "        self.filenames = filenames\n",
    "        self.transform = transform\n",
    "                \n",
    "        # read labels of each subject\n",
    "        self.labels = {}\n",
    "        with open(subjects_csv, \"r\") as fp:\n",
    "            csv_reader = csv.reader(fp, delimiter=\",\")\n",
    "            for row in csv_reader:\n",
    "                if row[0] == \"subject_id\":\n",
    "                    continue\n",
    "                id = row[0]\n",
    "                label = int(row[4])\n",
    "                # self.labels[id] = label\n",
    "                self.labels[id] = torch.zeros(2)\n",
    "                self.labels[id][label] = 1\n",
    "\n",
    "        # count how many label == 1\n",
    "        progress = 0\n",
    "        not_progress = 0\n",
    "        for filename in self.filenames:\n",
    "            id = re.search(r'subject_(\\d{3})-(\\d{4})', filename).group(2)\n",
    "            if self.labels[id][1] == 1:\n",
    "                progress += 1\n",
    "            else:\n",
    "                not_progress += 1\n",
    "        print(f\"Total subjects: {len(self.filenames)}, Progressing: {progress}, Not progressing: {not_progress}\")\n",
    "\n",
    "        # create image reader\n",
    "        self.image_reader = NibabelReader()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.filenames[idx]\n",
    "        # get subject id from filename using regex\n",
    "        id = re.search(r'subject_(\\d{3})-(\\d{4})', filename).group(2)\n",
    "        image = self.image_reader.read(os.path.join(self.data_dir, filename))\n",
    "        image = image.get_fdata().astype(np.float32)\n",
    "        image = torch.from_numpy(image)\n",
    "        # leave only middle 91 channels in dimension 1\n",
    "        image = image[:, 9:100, :]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = self.labels[id]\n",
    "\n",
    "        return {'image': image, 'label': label}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total subjects: 751, Progressing: 326, Not progressing: 425\n",
      "Total subjects: 75, Progressing: 33, Not progressing: 42\n",
      "Total subjects: 76, Progressing: 29, Not progressing: 47\n"
     ]
    }
   ],
   "source": [
    "from typing import Any\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# open files.txt which contains all the file paths\n",
    "with open('/home/minghui/github/NMSS/vitmae/files.txt', 'r') as f:\n",
    "    files = f.readlines()\n",
    "files = [x.strip() for x in files]\n",
    "\n",
    "data_dir = '/media/minghui/Data/Datasets/NMSS Study/yuxin/agg_normalized/'\n",
    "label_csv = '/home/minghui/github/NMSS/vitmae/subject_list.csv'\n",
    "\n",
    "# custom torch transform to select num_channels random channels\n",
    "class RandomChannelSelect:\n",
    "    def __init__(self, num_channels=8):\n",
    "        self.num_channels = num_channels\n",
    "\n",
    "    def __call__(self, img):\n",
    "        # img is a 4D tensor of shape (1, C, H, W)\n",
    "        # randomly select a starting channel\n",
    "        start_channel = np.random.randint(0, img.shape[0] - self.num_channels)\n",
    "        img = img[start_channel:start_channel+self.num_channels, :, :]\n",
    "        return img\n",
    "\n",
    "class RandomCrop3D:\n",
    "    def __init__(self, size=64):\n",
    "        self.size = size\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        # img is a 3D tensor of shape (x, y, z)\n",
    "        # randomly select a starting channel\n",
    "        x_start = np.random.randint(0, img.shape[0] - self.size)\n",
    "        y_start = np.random.randint(0, img.shape[1] - self.size)\n",
    "        z_start = np.random.randint(0, img.shape[2] - self.size)\n",
    "        img = img[x_start:x_start+self.size, y_start:y_start+self.size, z_start:z_start+self.size]\n",
    "        return img\n",
    "\n",
    "class RandomDimensionPermute:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, img):\n",
    "        # img is a 4D tensor of shape (1, C, H, W)\n",
    "        # randomly permute the dimensions\n",
    "        dims = ['x', 'y', 'z']\n",
    "        np.random.shuffle(dims)\n",
    "        img = rearrange(img, 'x y z -> {}'.format(' '.join(dims)))\n",
    "        return img\n",
    "\n",
    "custom_transforms = T.Compose([\n",
    "    RandomCrop3D(64),\n",
    "    RandomDimensionPermute(),\n",
    "    # RandomChannelSelect(16),\n",
    "    # T.RandomHorizontalFlip(),\n",
    "    # T.RandomVerticalFlip(),\n",
    "    # T.RandomAffine(15, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=(-10, 10, -10, 10)),\n",
    "    # T.RandomAdjustSharpness(0.5),\n",
    "    # T.GaussianBlur(3, sigma=(0.1, 0.5)),\n",
    "    # T.RandomRotation(90),\n",
    "    # T.RandomCrop(64),\n",
    "])\n",
    "\n",
    "# train_dataset = SPRINT_T1w_flat_Dataset(data_dir, files, label_csv, mode='train', transform=custom_transforms)\n",
    "# val_dataset = SPRINT_T1w_flat_Dataset(data_dir, val_set, label_csv, 'val', transform=custom_transforms)\n",
    "# test_dataset = SPRINT_T1w_flat_Dataset(data_dir, test_set, label_csv, 'test', transform=custom_transforms)\n",
    "\n",
    "train_dataset = SPRINT_T1w_flat_Dataset(data_dir, files, label_csv, mode='train')\n",
    "val_dataset = SPRINT_T1w_flat_Dataset(data_dir, val_set, label_csv, 'val')\n",
    "test_dataset = SPRINT_T1w_flat_Dataset(data_dir, test_set, label_csv, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total subjects: 751, Progressing: 326, Not progressing: 425\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4)\n",
    "\n",
    "# count number of progressing in train_dataset\n",
    "progress = 0\n",
    "for i in range(len(train_dataset)):\n",
    "    if train_dataset[i]['label'][1] == 1:\n",
    "        progress += 1\n",
    "total, nonprogress = len(train_dataset), len(train_dataset) - progress\n",
    "print(f\"Total subjects: {total}, Progressing: {progress}, Not progressing: {nonprogress}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.40465514076516984, Accuracy: 406/751, 54.06125259399414%\n",
      "Validation Accuracy: 42/75, 56.00000000000001%\n",
      "Epoch: 1, Loss: 0.3995908990185312, Accuracy: 425/751, 56.59120559692383%\n",
      "Validation Accuracy: 42/75, 56.00000000000001%\n",
      "Epoch: 2, Loss: 0.3995370668299655, Accuracy: 425/751, 56.59120559692383%\n",
      "Validation Accuracy: 42/75, 56.00000000000001%\n",
      "Epoch: 3, Loss: 0.3995909037742209, Accuracy: 425/751, 56.59120559692383%\n",
      "Validation Accuracy: 42/75, 56.00000000000001%\n",
      "Epoch: 4, Loss: 0.39953707253679316, Accuracy: 425/751, 56.59120559692383%\n",
      "Validation Accuracy: 42/75, 56.00000000000001%\n",
      "Epoch: 5, Loss: 0.3994294116471676, Accuracy: 425/751, 56.59120559692383%\n",
      "Validation Accuracy: 42/75, 56.00000000000001%\n",
      "Epoch: 6, Loss: 0.3995370715856552, Accuracy: 425/751, 56.59120559692383%\n",
      "Validation Accuracy: 42/75, 56.00000000000001%\n",
      "Epoch: 7, Loss: 0.3994832387629976, Accuracy: 425/751, 56.59120559692383%\n",
      "Validation Accuracy: 42/75, 56.00000000000001%\n",
      "Epoch: 8, Loss: 0.3996985611763406, Accuracy: 425/751, 56.59120559692383%\n",
      "Validation Accuracy: 42/75, 56.00000000000001%\n",
      "Epoch: 9, Loss: 0.39937557882450997, Accuracy: 425/751, 56.59120559692383%\n",
      "Validation Accuracy: 42/75, 56.00000000000001%\n",
      "Epoch: 10, Loss: 0.39953707221974716, Accuracy: 425/751, 56.59120559692383%\n",
      "Validation Accuracy: 42/75, 56.00000000000001%\n",
      "Epoch: 11, Loss: 0.399644728353683, Accuracy: 425/751, 56.59120559692383%\n",
      "Validation Accuracy: 42/75, 56.00000000000001%\n",
      "Epoch: 12, Loss: 0.3998062236511961, Accuracy: 425/751, 56.59120559692383%\n",
      "Validation Accuracy: 42/75, 56.00000000000001%\n",
      "Epoch: 13, Loss: 0.39975239019444647, Accuracy: 425/751, 56.59120559692383%\n",
      "Validation Accuracy: 42/75, 56.00000000000001%\n",
      "Epoch: 14, Loss: 0.3996985678343063, Accuracy: 425/751, 56.59120559692383%\n",
      "Validation Accuracy: 42/75, 56.00000000000001%\n",
      "Epoch: 15, Loss: 0.3996985611763406, Accuracy: 425/751, 56.59120559692383%\n",
      "Validation Accuracy: 42/75, 56.00000000000001%\n",
      "Epoch: 16, Loss: 0.3996447318411888, Accuracy: 425/751, 56.59120559692383%\n",
      "Validation Accuracy: 42/75, 56.00000000000001%\n",
      "Epoch: 17, Loss: 0.39937558072678586, Accuracy: 425/751, 56.59120559692383%\n",
      "Validation Accuracy: 42/75, 56.00000000000001%\n",
      "Epoch: 18, Loss: 0.39964473089005087, Accuracy: 425/751, 56.59120559692383%\n",
      "Validation Accuracy: 42/75, 56.00000000000001%\n",
      "Epoch: 19, Loss: 0.399375577873372, Accuracy: 425/751, 56.59120559692383%\n",
      "Validation Accuracy: 42/75, 56.00000000000001%\n",
      "Epoch: 20, Loss: 0.39942940911079977, Accuracy: 425/751, 56.59120559692383%\n",
      "Validation Accuracy: 42/75, 56.00000000000001%\n",
      "Epoch: 21, Loss: 0.3995370687322414, Accuracy: 425/751, 56.59120559692383%\n",
      "Validation Accuracy: 42/75, 56.00000000000001%\n",
      "Epoch: 22, Loss: 0.3996447337434647, Accuracy: 425/751, 56.59120559692383%\n",
      "Validation Accuracy: 42/75, 56.00000000000001%\n",
      "Epoch: 23, Loss: 0.3996447318411888, Accuracy: 425/751, 56.59120559692383%\n",
      "Validation Accuracy: 42/75, 56.00000000000001%\n",
      "Epoch: 24, Loss: 0.3994294116471676, Accuracy: 425/751, 56.59120559692383%\n",
      "Validation Accuracy: 42/75, 56.00000000000001%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭──────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_591117/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">1222266463.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">68</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_591117/1222266463.py'</span>                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_591117/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">1222266463.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">26</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_591117/1222266463.py'</span>                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/minghui/github/transformers/.env/lib/python3.10/site-packages/torch/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_tensor.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">487</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">backward</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 484 │   │   │   │   </span>create_graph=create_graph,                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 485 │   │   │   │   </span>inputs=inputs,                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 486 │   │   │   </span>)                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 487 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>torch.autograd.backward(                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 488 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, gradient, retain_graph, create_graph, inputs=inputs              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 489 │   │   </span>)                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 490 </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/minghui/github/transformers/.env/lib/python3.10/site-packages/torch/autograd/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">__init</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">__.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">200</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">backward</span>                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">197 │   # The reason we repeat same the comment below is that</span>                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">198 │   # some Python versions print out the first line of a multi-line function</span>        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">199 │   # calls in the traceback and some print out the last line</span>                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>200 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>Variable._execution_engine.run_backward(  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Calls into the C++ engine to run th</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">201 │   │   </span>tensors, grad_tensors_, retain_graph, create_graph, inputs,                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">202 │   │   </span>allow_unreachable=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>, accumulate_grad=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Calls into the C++ engine </span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">203 </span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰───────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m─────────────────────────── \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m ───────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_591117/\u001b[0m\u001b[1;33m1222266463.py\u001b[0m:\u001b[94m68\u001b[0m in \u001b[92m<module>\u001b[0m                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_591117/1222266463.py'\u001b[0m                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_591117/\u001b[0m\u001b[1;33m1222266463.py\u001b[0m:\u001b[94m26\u001b[0m in \u001b[92mtrain\u001b[0m                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_591117/1222266463.py'\u001b[0m                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/minghui/github/transformers/.env/lib/python3.10/site-packages/torch/\u001b[0m\u001b[1;33m_tensor.py\u001b[0m:\u001b[94m487\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mbackward\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 484 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mcreate_graph=create_graph,                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 485 \u001b[0m\u001b[2m│   │   │   │   \u001b[0minputs=inputs,                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 486 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 487 \u001b[2m│   │   \u001b[0mtorch.autograd.backward(                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 488 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m, gradient, retain_graph, create_graph, inputs=inputs              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 489 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 490 \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/minghui/github/transformers/.env/lib/python3.10/site-packages/torch/autograd/\u001b[0m\u001b[1;33m__init\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33m__.py\u001b[0m:\u001b[94m200\u001b[0m in \u001b[92mbackward\u001b[0m                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m197 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# The reason we repeat same the comment below is that\u001b[0m                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m198 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# some Python versions print out the first line of a multi-line function\u001b[0m        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m199 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# calls in the traceback and some print out the last line\u001b[0m                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m200 \u001b[2m│   \u001b[0mVariable._execution_engine.run_backward(  \u001b[2m# Calls into the C++ engine to run th\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m201 \u001b[0m\u001b[2m│   │   \u001b[0mtensors, grad_tensors_, retain_graph, create_graph, inputs,                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m202 \u001b[0m\u001b[2m│   │   \u001b[0mallow_unreachable=\u001b[94mTrue\u001b[0m, accumulate_grad=\u001b[94mTrue\u001b[0m)  \u001b[2m# Calls into the C++ engine \u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m203 \u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰───────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mKeyboardInterrupt\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from einops import rearrange\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def train(model, train_loader, val_loader, optimizer, loss_fn, scheduler, epochs):\n",
    "    loss_hist = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # training\n",
    "        model.train()\n",
    "        train_correct = train_total = 0\n",
    "        for batch_idx, datum in enumerate(train_loader):\n",
    "            image = datum['image'].cuda()\n",
    "            label = datum['label'].cuda()\n",
    "            # print('[debug] label: ', label)\n",
    "            # print('[debug] label.shape: ', label.shape)\n",
    "            # print('[debug] image.shape: ', image.shape)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(image)\n",
    "            # pass through softmax\n",
    "            output = F.softmax(output.logits, dim=-1)\n",
    "            # print('[debug] output.shape: ', output.shape)\n",
    "\n",
    "            loss = loss_fn(output, label)\n",
    "            loss_hist.append(loss.item())\n",
    "            loss.backward()\n",
    "            # train accuracy\n",
    "            pred = output.argmax(dim=-1)\n",
    "            label = label.argmax(dim=-1)\n",
    "            train_correct += (pred == label).sum()\n",
    "            train_total += label.shape[0]\n",
    "            optimizer.step()\n",
    "        scheduler.step()\n",
    "        # avg loss \n",
    "        avg_loss = sum(loss_hist) / len(loss_hist)\n",
    "        loss_hist.clear()\n",
    "        acc = train_correct / train_total\n",
    "        print(f'Epoch: {epoch}, Loss: {avg_loss}, Accuracy: {train_correct}/{train_total}, {acc*100}%')\n",
    "\n",
    "        # validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_correct = val_total = 0\n",
    "            for batch_idx, datum in enumerate(val_loader):\n",
    "                image = datum['image'].cuda()\n",
    "                label = datum['label'].cuda()\n",
    "                output = model(image)\n",
    "                output = F.softmax(output.logits, dim=-1)\n",
    "\n",
    "                pred = output.argmax(dim=-1)\n",
    "                label = label.argmax(dim=-1)\n",
    "                val_correct += (pred == label).sum().item()\n",
    "                val_total += label.size(0)\n",
    "            val_acc = val_correct / val_total\n",
    "            print(f'Validation Accuracy: {val_correct}/{val_total}, {val_acc*100}%')\n",
    "\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss, BCELoss\n",
    "\n",
    "model = model.cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "normalized_class_weights = torch.tensor([progress/total, nonprogress/total]).cuda()\n",
    "loss_fn = CrossEntropyLoss(weight=normalized_class_weights)\n",
    "# loss_fn = BCELoss()\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.5)\n",
    "\n",
    "epochs = 400\n",
    "train(model, train_loader, val_loader, optimizer, loss_fn, scheduler, epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
